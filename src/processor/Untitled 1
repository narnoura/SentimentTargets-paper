	
		// Not an xml file
		/*Document source_doc = FileReader.ReadXMLFile(source_file, "english");
		source_doc.getDocumentElement().normalize();
		NodeList post_list = source_doc.getElementsByTagName("post");
		for (int c=0;c < post_list.getLength(); c++) {
			Node n_node = post_list.item(c);
			Element e_element = (Element) n_node;
			String author = e_element.getAttribute("author");
			String post_id = e_element.getAttribute("id");
			//String text = e_element.getElementsByTagName("text").item(0).getTextContent();
			//String text = e_element.getElementsByTagName("post").item(0).getTextContent();
			//String text = n_node.getTextContent();
			String text = e_element.getTextContent();
			System.out.println("Post text before removing quotes:");
			// Ignore quotes from different authors
			// actually if we remove the quotes we won't have access to offset any longer
			// even if we get rid of the 'post' tags we won't
			NodeList quotes = e_element.getElementsByTagName("quote");
			for (int q=0;q<quotes.getLength();q++) {
				Node quote = quotes.item(q);
				String quote_text = quote.getTextContent();
				text = text.replace(quote_text, "");
			}
			text = text.replaceAll("<quote", "");
			text = text.replaceAll("/quote>", "");
			text = text.trim();  //
			text = Tokenizer.RemoveNewLines(text);  //
			System.out.println("Post text after removing quotes:" + text);
				
			Comment comment = new Comment(doc_id, text);
			comment.SetAuthor(author);
			comment.SetPostId(post_id);
			comment.SetOriginalText(original_text);
			List<Token> tokens = comment.Tokenize("word");
			comment.SetTokens(tokens); 
			for (Token t: comment.tokens_) {
				t.SetTargetOffset(-1);
			}*/
			//comments.add(comment);
		//}
		
		
		// should update comments
	public void ReadAnnotations(String annotation_file) {
		if (this.comments.isEmpty()) {
			System.out.println("Comments are empty. Please read DEFT source file first\n");
			return;
		}
		Document annotation_doc = FileReader.ReadXMLFile(annotation_file, "english");
		annotation_doc.getDocumentElement().normalize();
		Node sentiment_annotations =  
				annotation_doc.getElementsByTagName("sentiment_annotations").item(0);
		Element sentiment = (Element) sentiment_annotations;
		NodeList entities = sentiment.getElementsByTagName("entity");
		NodeList relations = sentiment.getElementsByTagName("relations");
		NodeList events = sentiment.getElementsByTagName("events");
		
		// Can also
		// Go over the whole post (doc)
		// for each entity, create target using start offset + length
		// Set target offsets for these words to 1 and all others to -1
		// Now we know where it occurs in the doc.
		// So can keep comment = doc
		// Then see if we can separate out posts in training data (keep pointer or post text arrays)
		
		// Read entity annotations
		// Need to do same loop for events and relations?
		for (int e=0; e<entities.getLength(); e++) {
			Node e_node = entities.item(e);
			Element entity = (Element) e_node;
			String ere_id = entity.getAttribute("ere_id");
			String entity_text = entity.getAttributeNode("text").getTextContent();
			String offset = entity.getAttribute("offset");
			String length = entity.getAttribute("length");
			Node sentiment_node = entity.getAttributeNode("sentiment");
			Element sentiment_element = (Element) sentiment_node;
			String polarity = sentiment_element.getAttribute("polarity");
			String sarcasm = sentiment_element.getAttribute("sarcasm");
			System.out.println("Entity: " + entity_text);
			System.out.println("Sentiment: " + polarity);
			Node source_node = sentiment_element.getAttributeNode("source");
			Element source_element = (Element) source_node;
			String source_id = source_element.getAttribute("ere_id");
			
			// Update the comments that contain these entities
			for (Comment c: comments) {
				String post_text = c.raw_text_;
				int post_start_offset = c.original_text.indexOf(post_text);
				int post_end_offset = c.original_text.lastIndexOf(post_text,post_start_offset);
				System.out.println("Post offsets of comment: "
				+ post_start_offset + " " + post_end_offset); 
				if (post_text.contains(entity_text)) {
					System.out.println("Found text. Annotated offset of entity: " + offset);
					if (Integer.parseInt(offset) <= post_end_offset 
							&& Integer.parseInt(offset) >= post_start_offset) {
						System.out.println("Found target!");
						DeftTarget dt = (DeftTarget) new Target(polarity,entity_text);
						dt.SetDeftOffset(offset);
						dt.SetSarcasm(sarcasm);
						dt.SetLength(length);
						dt.SetSourceID(source_id);
						List<Token> target_tokens = Tokenizer.SimpleTokenize(entity_text, "word");
						
						List<Integer> comment_offsets = c.Find(entity_text, target_tokens);
						dt.SetTokens(target_tokens);
						if (!comment_offsets.isEmpty()) {	
							dt.SetOffsets(comment_offsets);
							// Update offsets in comment tokens. 
							for (int o: comment_offsets) {
									System.out.println("offset: " + o);
									for (int k=0; k<target_tokens.size(); k++) {
										Token token_with_target = c.tokens_.get(k+o);
										token_with_target.SetTargetOffset(k);
										token_with_target.SetSentiment(polarity);
									}
							}
							c.AddTarget(dt);
							if (comment_offsets.size() > 1) {
								System.out.println("Uh oh. Found multiple targets in post. Which offset "
										+ "should I use?\n");
								System.out.println("Target:" + entity_text);
								System.exit(0);
							}
					    } 
					break; // found in the post we want
					}
					
					else {
						System.out.println("Didn't find target!");
					}
					
				}
			}
		}
		
	}
	
	
	// more DEFTInputReader backup
					/*if (!dtarg.comment_offsets_.isEmpty()) {	
							dtarg.SetOffsets(dtarg.comment_offsets);
							// Update offsets in comment tokens. 
							for (int o: comment_offsets) {
									System.out.println("offset: " + o);
									for (int k=0; k<target_tokens.size(); k++) {
										Token token_with_target = c.tokens_.get(k+o);
										token_with_target.SetTargetOffset(k);
										token_with_target.SetSentiment(polarity);
									}
							}
							c.AddTarget(dtarg);
							if (comment_offsets.size() > 1) {
								System.out.println("Uh oh. Found multiple targets in post. Which offset "
										+ "should I use?\n");
								System.out.println("Target:" + entity_text);
								System.exit(0);
							}