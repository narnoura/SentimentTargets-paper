/**
 * This is a backup FeatureExtractor.java
 */
package models;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;

import data.Comment;
import data.Target;
import data.Token;
import models.baselines.ALL_NP;
import processor.LexiconProcessor;
import processor.Sentiment;


/**
 * @author Narnoura
 * Extract features from comments.
 *
 */
public class FeatureExtractor {

	// Can be mada comments, or any comments
	public List<Comment> input_comments;
	// Used if input comments are tokenized comments
	public List<Comment> nontok_comments;
	
	public LexiconProcessor lp;
	
	// feature types
	// Word, POS (madamira for now. can also try stanford since ATB normalized space), 
	// madamira features (lex, asp, mod, stt, cas?, gen? mod? all?)
	// Sentiment (pos score, neg score, neut score)
	// Later, syntax, dependency and topic features
	// Can have different feature sets.
	// FS1: Word, POS
	// FS2: Word, POS, madamira all
	// FS3: Word, POS, sentiment
	// FS4: Word, POS, madamira select
	// FS5: all
	public List<String> binary_feature_types;
	public List<String> continuous_feature_types;
	//TODO more efficient set
	public List<String> morphological_features = Arrays.asList("gloss","prc3", "prc2", "prc1",
			"prc0", "per", "asp", "vox", "mod", "gen", "num", "stt", "cas", "enc0", "rat", "source", 
			"stemcat");
	
	public static boolean include_labels = true;
	public static boolean exclude_undetermined = false;
	
	public FeatureExtractor() {
		binary_feature_types = new ArrayList<String>();
		continuous_feature_types = new ArrayList<String>();
		//binary_feature_types.add("Word");
		//binary_feature_types.add("MadamiraPOS");
		
	}
	
	public FeatureExtractor(List<Comment> input_comments) {
		this.input_comments = input_comments;
		binary_feature_types = new ArrayList<String>();
		continuous_feature_types = new ArrayList<String>();
		/*if (binary_feature_types.isEmpty() 
				&& continuous_feature_types.isEmpty()) {
			System.out.println("Warning: No features specified. Defaulting to"
					+ "features: Word, MadamiraPOS \n");*/
		//binary_feature_types.add("Word");
		//binary_feature_types.add("MadamiraPOS");
		

	}
	
	public void SetBinaryFeatures (List<String> binary_features) {
		this.binary_feature_types = binary_features;
	}
	
	public void SetContinuousFeatures (List<String> continuous_features) {
		this.continuous_feature_types = continuous_features;
	}

	
	public void SetLexiconProcessor (LexiconProcessor lp) {
		this.lp = lp;
		if (this.binary_feature_types.contains("Sentiment")) {
			System.out.println("Reading sentiment lexicons \n");
			lp.ReadSlsa(lp.lexicon_files.get("Slsa"));
			lp.ReadArsenl(lp.lexicon_files.get("Arsenl"));
			lp.ReadSifaat(lp.lexicon_files.get("Sifaat"));
		}
	}
	
	public void SetNontokenized (List<Comment> comments) {
		nontok_comments = comments;
	}
	
	List<List<String>> Data (Comment c) {
	
		List<List<String>> data = new ArrayList<List<String>>();
		
		List<List<String>> basic_features = ExtractBasicFeatures(c);
		List<List<String>> bin_features = ExtractBinaryFeatures(c);
		List<String> labels = new ArrayList<String>();
		if (include_labels) {
			labels = ExtractTokenTargetLabels(c);
			assert(c.tokens_.size() == labels.size());
		}
		
		assert(c.tokens_.size() == basic_features.size());
		assert(c.tokens_.size() == bin_features.size());
		
		for (int t=0; t< c.tokens_.size(); t++) {
			List<String> features = new ArrayList<String>();
			List<String> basic_token_features = basic_features.get(t);
			List<String> bin_token_features = bin_features.get(t);
			features.addAll(basic_token_features);
			features.addAll(bin_token_features);
			if (include_labels) {
				features.add(labels.get(t));
			}
			data.add(features);
		}
		return data;
	}
	
	// Extracted by default
	// Extracts only word, POS, and parse tree if available
	// Can also add stanford POS for ATB tokens
	List<List<String>> ExtractBasicFeatures (Comment c) {
		List<List<String>> basic_features = new ArrayList<List<String>>();
	
		for (Token t: c.tokens_) {
			List<String> token_features = new ArrayList<String>();
			String word = t.text_;
			//System.out.println("FeatureExtractor: Token:" + t.text_);
			/*if (!t.morph_features.containsKey("NO_ANALYSIS")) {
				System.out.println("FeatureExtractor: pos:" 
			          + t.morph_features.get("pos"));
			}*/
			// surface word, lemma, or stem
			if (this.binary_feature_types.contains("Word")) {
			token_features.add(word);
			}
			else if (this.binary_feature_types.contains("Lex")) {
				if (t.morph_features.containsKey("lex") && (t.clitic.equals("none") ||
						t.clitic.equals("word"))) {
					token_features.add(t.morph_features.get("lex"));
				}
				else {
					token_features.add(word);
				}
			}
			else if (this.binary_feature_types.contains("Stem") ) {
				if (t.morph_features.containsKey("stem") && (t.clitic.equals("none") ||
						t.clitic.equals("word"))) {
					token_features.add(t.morph_features.get("stem"));
				}
				else {
					token_features.add(word);
				}
			}
			else { // default
				token_features.add(word);
			}
			// madamira pos
			if (t.morph_features.containsKey("NO_ANALYSIS")) {
				token_features.add("NO_ANALYSIS");
			}
			else {
			//String pos = t.morph_features.get("pos");
			String pos = t.pos_;
			token_features.add(pos);
			}
			if (t.parse_tree != null) {
				token_features.add(t.parse_tree);
			}
			basic_features.add(token_features);
		}
		
		return basic_features;
	}
	
	// Includes lexical, dict, morphological, semantic or any binary features
	// Put features in outer loop instead? (less if statements). 
	// Then we have to save the token features per token (e.g hash)
	List<List<String>> ExtractBinaryFeatures (Comment c) {
		List<List<String>> bin_features = new ArrayList<List<String>>();
	
		
		for (Token t: c.tokens_) {
			List<String> token_features = new ArrayList<String>();
			for (String feature : this.binary_feature_types) {
				// First, morphological features
				// System.out.println("Feature:" + feature);
				if (feature.equals("MadamiraPos") || feature.equals("Word") 
						|| feature.equals("pos")) {
					// || feature.equals("Stem") || feature.equals("lex")
					// For now these are added by default
					continue; 
				}
				// TODO: more efficient, separate Extractmorphological or 
				// morph_features.containsKey
				/*try {
					if (t.morph_features.containsKey("NO_ANALYSIS") 
							&& morphological_features.contains(feature)) {
						token_features.add("NO_ANALYSIS");
					}
					else if (t.morph_features.containsKey(feature)) {
						token_features.add(t.morph_features.get(feature));
					}
				}
				catch (Exception e) {
					e.printStackTrace();
				}*/
				
				// Then sentiment features    separate function for semantic features?
				// ...
				// poshigh, poslow, poszero, neghigh, neglow, negzero
				else if (feature.equals("Sentiment")) {
				  // HashMap<String,String> sentfeat = 
				    //		Sentiment.GetTokenBinarySentimentFeaturesArsenl(t, lp, 0.1);
				  String sentfeat = 
				    	Sentiment.GetTokenHighLowSentimentFeaturesArsenl(t, lp, 0.1);
					//HashMap<String,String> sentfeat = 
						//    	Sentiment.GetSentimentScoreFeaturesArsenl(t, lp);
					
				  //String sentfeat = Sentiment.GetSentimentSifaat(t, lp).toString();
					//String sentfeat = Sentiment.GetBinarySentimentSifaat(t, lp).toString();
				  
				  token_features.add(sentfeat);
				   
				 /* token_features.add(sentfeat.get("pos"));
				  token_features.add(sentfeat.get("neg"));
				  token_features.add(sentfeat.get("neut"));*/
				}
				else if (feature.equals("NER")) {
					token_features.add(t.NER);
					/*if (!t.NER.equals("O") && t.NER != null) {
						token_features.add("1");
					}
					else if (t.NER.equals("O")) {
						token_features.add("0");
					}*/
				}
				else if (feature.equals("BPC")) {
					// if BPC is not null
					token_features.add(t.BPC);
				}
				
				// Then, LIWC features, topic features ...
			}
			bin_features.add(token_features);
		}
		
		return bin_features;
	}

	
	// return type string?
	List<List<Double>> ExtractNumericFeatures (Comment c) {
		List<List<Double>> numeric_features = new ArrayList<List<Double>>();
		
		return numeric_features;
	}
	
	// Extracts token labels for target tagging (T, O)
	List<String> ExtractTokenTargetLabels (Comment c) {
		List<String> labels = new ArrayList<String>();
		
		for (Token t: c.tokens_) {
			if (t.target_offset_ == -1) {
				labels.add("O");
			} 
			else if (t.target_offset_ >= 0) {
				if (exclude_undetermined && t.sentiment_.equals("undetermined")) {
					labels.add("O");
				}
				else {
					labels.add("T");
				}
				//System.out.println("Target offset:" + t.target_offset_);
			}
			else {
				System.out.println("Feature Extractor: No valid target offset for"
						+ "token " + t.text_ + "for Comment" + c.comment_id_);
				System.exit(0);
			}
		}
		
		return labels;
	}
	
	// Extracts token labels for target tagging (BT, IT, O)
	//
	// TODO: exclude undetermined sentiment
	List<String> ExtractBIOTokenTargetLabels (Comment c) {
		List<String> labels = new ArrayList<String>();
		
		for (Token t: c.tokens_) {
			if (t.target_offset_ == -1) {
				labels.add("O");
			} 
			else if (t.target_offset_ == 0) {
				if (exclude_undetermined && t.sentiment_.equals("undetermined")) {
					labels.add("O");
				}
				else {
					labels.add("BT");
				}
			}
			else if (t.target_offset_ > 0) {
				if (exclude_undetermined && t.sentiment_.equals("undetermined")) {
					labels.add("O");
				}
				else {
					labels.add("IT");
				}		
			}
			else {
				System.out.println("Feature Extractor: No valid target offset for"
						+ "token " + t.text_ + "for Comment" + c.comment_id_);
				System.exit(0);
			}
		}
		
		return labels;
	}
	
	List<String> ExtractTokenSentimentLabels (Comment c) {
		List<String> labels = new ArrayList<String>();
		
		// The target offsets here are assumed to be predicted
		for (Token t: c.tokens_) {
			if (t.target_offset_ == -1) {
				labels.add("O");
				// TODO how to exclude?
			} 
			else if (t.target_offset_ >= 0) {
				String sentiment = t.sentiment_;
				if (sentiment == null || sentiment.isEmpty()) {
					System.out.println("Feature Extractor: Token is part of a target but has"
							+ "no sentiment: "
							+ "token: " + t.text_ + "for Comment: " + c.comment_id_);
					System.exit(0);
				}
				
				if (exclude_undetermined && sentiment.equals("undetermined")) {
					labels.add("O");
				}
				else {
				labels.add(sentiment);
				}
			}
			else {
				System.out.println("Feature Extractor: No valid target offset for"
						+ "token " + t.text_ + "for Comment" + c.comment_id_);
				System.exit(0);
			}
		}
		
		return labels;
	}
	


}
